{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "LSTM_wordpredictor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1d0792dd50984ce288a09351c5f9e22a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "state": {
            "_view_name": "TextView",
            "style": "IPY_MODEL_b9fac07857d8454eb46c951e2375d2d0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "TextModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "so she was considering in her own mind",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02319fc0703d40408554b7326fc1a101"
          }
        },
        "b9fac07857d8454eb46c951e2375d2d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02319fc0703d40408554b7326fc1a101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Subho95/Next_Word_Predictor/blob/master/LSTM_wordpredictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkXTxvOIxlww",
        "colab_type": "text"
      },
      "source": [
        "# Build Next word predictor using LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KotVUGfYxlw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########### import all libraries\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/')\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "%matplotlib inline\n",
        "import pickle\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import os\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, Activation\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1FyTXtnxlxA",
        "colab_type": "text"
      },
      "source": [
        "## Create a function that will extract the data from the dataset\n",
        "Next, we download the training data. The popular book “Alice’s Adventures in Wonderland” written by Lewis Caroll has been used as training dataset for this project. The e-book can be downloaded from http://www.gutenberg.org/files/11/11-0.txt in Plain Text UTF-8 format. The downloaded book has been stored in the root directory with the name ‘wonderland.txt’. We open this book using the open command and convert all characters into lowercase (so as to reduce the number of characters in the vocabulary, making it easier to learn for the model.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BPEfCVey0cM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############### Download CIFAR-10 data and save it to google drive\n",
        "import requests  \n",
        "file_url = \"http://www.gutenberg.org/files/11/11-0.txt\"\n",
        "    \n",
        "r = requests.get(file_url, stream = True)  \n",
        "  \n",
        "with open(\"/content/drive/My Drive/DeepNN_HandsOn/Alice_in_won.txt\", \"wb\") as file:  \n",
        "    for block in r.iter_content(chunk_size = 1024): \n",
        "         if block:  \n",
        "             file.write(block)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCs2rpm3xlxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############# Read file data\n",
        "file = open(\"/content/drive/My Drive/DeepNN_HandsOn/Alice_in_won.txt\", encoding = 'utf8')\n",
        "raw_text = file.read()    #you need to read further characters as well\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8teR2EhlxlxF",
        "colab_type": "text"
      },
      "source": [
        "## Creating Vocabulary\n",
        "\n",
        "Next, we store all the distinct characters occurring in the book in the chars variable. We also remove some of the rare characters (stored in bad-chars) from the book. The final vocabulary of the book is printed at the end of code segment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NPaBdiOqxlxH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0aa26753-049e-43c6-ea90-1c6aa5fff8c1"
      },
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "print(chars)\n",
        "bad_chars = ['#', '*', '@', '_', '\\ufeff']\n",
        "for i in range(len(bad_chars)):\n",
        "    raw_text = raw_text.replace(bad_chars[i],\"\")\n",
        "\n",
        "chars = sorted(list(set(raw_text)))\n",
        "print(chars)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\n', ' ', '!', '#', '$', '%', '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '‘', '’', '“', '”', '\\ufeff']\n",
            "['\\n', ' ', '!', '$', '%', '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '‘', '’', '“', '”']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LENojSYnXlv",
        "colab_type": "text"
      },
      "source": [
        "# Summarize entire text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBmSTrm5xlxK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "43fe890c-910c-44fc-a8bb-cbbed20d5730"
      },
      "source": [
        "text_length = len(raw_text)\n",
        "char_length = len(chars)\n",
        "VOCABULARY = char_length\n",
        "SEQ_LENGTH =100\n",
        "print(\"Text length = \" + str(text_length))\n",
        "print(\"No. of characters = \" + str(char_length))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text length = 163721\n",
            "No. of characters = 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TYiOICYnnpB",
        "colab_type": "text"
      },
      "source": [
        "# Preprocess data\n",
        "\n",
        "Now, we need to modify the dataset representation to bring it in the form the model will need. So, we create an input window of 100 characters (SEQ_LENGTH = 100) and shift the window one character at a time until we reach the end of the book. An encoding is used, so as to map each of the characters into it’s corresponding location in the vocabulary. Each time the input window contains a new sequence, it is converted into integers, using this encoding and appended to the input list of the dataset, input_strings. For all such input windows, the character just following the sequence is appended to the output list output_strings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuajbwX4xlxO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4f152bc9-deb0-4530-c349-9f82064fe3b3"
      },
      "source": [
        "\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "input_strings = []\n",
        "output_strings = []\n",
        "\n",
        "for i in range(len(raw_text) - SEQ_LENGTH):\n",
        "    X_text = raw_text[i: i + SEQ_LENGTH]\n",
        "    X = [char_to_int[char] for char in X_text]\n",
        "    input_strings.append(X)    \n",
        "    Y = raw_text[i + SEQ_LENGTH]\n",
        "    output_strings.append(char_to_int[Y])\n",
        "# The input_strings and output_strings lists are converted into a numpy array of required dimensions, so that they can be fed to the model for the training.\n",
        "length = len(input_strings)\n",
        "input_strings = np.array(input_strings)\n",
        "input_strings = np.reshape(input_strings, (input_strings.shape[0], input_strings.shape[1], 1))\n",
        "input_strings = input_strings/float(VOCABULARY)\n",
        "\n",
        "output_strings = np.array(output_strings)\n",
        "output_strings = np_utils.to_categorical(output_strings)\n",
        "print(input_strings.shape)\n",
        "print(output_strings.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(163621, 100, 1)\n",
            "(163621, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM99mYFNoxLO",
        "colab_type": "text"
      },
      "source": [
        "# Design the Model\n",
        "\n",
        "We define the model now. The model is given an input of 100 character sequences and it outputs the respective probabilities with which a character can succeed the input sequence. The model consists of 3 hidden layers. The first two hidden layers consist of 256 LSTM cells, and the second layer is fully connected to the third layer. The number of neurons in the third layer is same as the number of unique characters in the training set (the vocabulary of the training set). The neurons in the third layer, use softmax activation so as to convert their outputs into respective probabilities. The loss used is Categorical cross entropy and the optimizer used is Adam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnT57-UvDpUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def buildmodel(VOCABULARY):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(256, input_shape = (SEQ_LENGTH, 1), return_sequences = True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(256))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(VOCABULARY, activation = 'softmax'))\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypwHWDluwXoj",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOLfKy1nxlxc",
        "colab_type": "text"
      },
      "source": [
        "## Running the model\n",
        "\n",
        "You can try different layouts to improve the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q-SEJkhxlxe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a8c23680-eb8b-4192-9a6a-2162bf932a18"
      },
      "source": [
        "filepath=\"/content/drive/My Drive/DeepNN_HandsOn/LSTM_saved_models/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "model = buildmodel(VOCABULARY)\n",
        "history = model.fit(input_\n",
        "strings\n",
        "strings, output_strings, epochs = 5, batch_size = 128, callbacks = callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "163621/163621 [==============================] - 359s 2ms/step - loss: 2.9064\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.90637, saving model to /content/drive/My Drive/DeepNN_HandsOn/LSTM_saved_models/weights-improvement-01-2.9064.hdf5\n",
            "Epoch 2/5\n",
            "163621/163621 [==============================] - 358s 2ms/step - loss: 2.5972\n",
            "\n",
            "Epoch 00002: loss improved from 2.90637 to 2.59722, saving model to /content/drive/My Drive/DeepNN_HandsOn/LSTM_saved_models/weights-improvement-02-2.5972.hdf5\n",
            "Epoch 3/5\n",
            " 66944/163621 [===========>..................] - ETA: 3:34 - loss: 2.4552"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8Y-uqdWxlxi",
        "colab_type": "text"
      },
      "source": [
        "## Next word Prediction\n",
        "\n",
        "The original model has been defined in a manner to take in 100 character inputs. So when the user initially starts typing the words, the total length of input string will be less than 100 characters. To solve this issue, the input has been padded with series of spaces in the beginning in order to make the total length of 100 characters. As the total length exceeds 100 characters, only last 100 characters are taken into consideration as the LSTM nodes take care of remembering the context of the document from before.\n",
        "\n",
        "Succeeding characters are predicted by the model until a space or full stop is encountered. The predicted characters are joined to form the next word, predicted by the mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDM2iaxigz6l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "082fc586-5cbf-467e-a820-a4a305a422b0"
      },
      "source": [
        "####### load weights\n",
        "model = buildmodel(VOCABULARY)\n",
        "model.load_weights(\"/content/drive/My Drive/DeepNN_HandsOn/LSTM_saved_models/weights-improvement-50-1.3195.hdf5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umjiY-MUxlxj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "1d0792dd50984ce288a09351c5f9e22a",
            "b9fac07857d8454eb46c951e2375d2d0",
            "02319fc0703d40408554b7326fc1a101"
          ]
        },
        "outputId": "31b8575e-1721-416e-c52d-078da7e2766c"
      },
      "source": [
        "import ipywidgets as widgets\n",
        "original_text = []\n",
        "predicted_text = []\n",
        "\n",
        "text = widgets.Text()\n",
        "display(text)\n",
        "\n",
        "def handle_submit(sender):\n",
        "    global predicted_text\n",
        "    global original_text\n",
        "    \n",
        "    inp = list(text.value)\n",
        "    \n",
        "    last_word = inp[len(original_text):]\n",
        "    inp = inp[:len(original_text)]    \n",
        "    original_text = text.value    \n",
        "    last_word.append(' ')\n",
        "    \n",
        "    inp_text = [char_to_int[c] for c in inp]\n",
        "    last_word = [char_to_int[c] for c in last_word]\n",
        "    \n",
        "    if len(inp_text) > 100:\n",
        "        inp_text = inp_text[len(inp_text)-100: ]\n",
        "    if len(inp_text) < 100:\n",
        "        pad = []\n",
        "        space = char_to_int[' ']\n",
        "        pad = [space for i in range(100-len(inp_text))]\n",
        "        inp_text = pad + inp_text\n",
        "    \n",
        "    while len(last_word)>0:\n",
        "        X = np.reshape(inp_text, (1, SEQ_LENGTH, 1))\n",
        "        next_char = model.predict(X/float(VOCABULARY))\n",
        "        inp_text.append(last_word[0])\n",
        "        inp_text = inp_text[1:]\n",
        "        last_word.pop(0)\n",
        "    \n",
        "    next_word = []\n",
        "    next_char = ':'\n",
        "    while next_char != ' ':\n",
        "        X = np.reshape(inp_text, (1, SEQ_LENGTH, 1))\n",
        "        next_char = model.predict(X/float(VOCABULARY))\n",
        "        index = np.argmax(next_char)        \n",
        "        next_word.append(chars[index])\n",
        "        inp_text.append(index)\n",
        "        inp_text = inp_text[1:]\n",
        "        next_char = chars[index]\n",
        "    \n",
        "    predicted_text = predicted_text + [''.join(next_word)]\n",
        "    print(\" \" + ''.join(next_word), end='|')\n",
        "    \n",
        "text.on_submit(handle_submit)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d0792dd50984ce288a09351c5f9e22a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Text(value='')"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            " the | tp | fand | degan | and |"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IIid0pRVHlFU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "8cf97f6d-da34-4068-ef90-2a240ba44817"
      },
      "source": [
        "#view images\n",
        "gen = datagen.flow(x_train, y_train, batch_size=64)\n",
        "x,y = gen.next()\n",
        "image = x[0].astype('uint')\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f067f9f3fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM6yZInNVvmsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsX2u30Cxlxm",
        "colab_type": "text"
      },
      "source": [
        "## Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiOYH81Rxlxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "batch_size = 64\n",
        "\n",
        "opt_rms = keras.optimizers.rmsprop(lr=0.001, decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=opt_rms, \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2l2ZsBPxlxr",
        "colab_type": "text"
      },
      "source": [
        "## Training the algorithm\n",
        "I would suggest more than 100 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwDle_bqxlxs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "3af66001-9067-495d-e4d1-6f68e526d3ec"
      },
      "source": [
        "epochs = 20\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.5651 - acc: 0.4483 - val_loss: 1.6769 - val_acc: 0.4055\n",
            "Epoch 2/20\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.5130 - acc: 0.4628 - val_loss: 1.3075 - val_acc: 0.5514\n",
            "Epoch 3/20\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 1.4965 - acc: 0.4680 - val_loss: 1.7274 - val_acc: 0.4102\n",
            "Epoch 4/20\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.4838 - acc: 0.4785 - val_loss: 1.2818 - val_acc: 0.5297\n",
            "Epoch 5/20\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.4747 - acc: 0.4743 - val_loss: 1.3360 - val_acc: 0.5152\n",
            "Epoch 6/20\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.4550 - acc: 0.4838 - val_loss: 1.2076 - val_acc: 0.5693\n",
            "Epoch 7/20\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.4521 - acc: 0.4856 - val_loss: 1.3794 - val_acc: 0.5148\n",
            "Epoch 8/20\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 1.4465 - acc: 0.4882 - val_loss: 1.3995 - val_acc: 0.4925\n",
            "Epoch 9/20\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.4456 - acc: 0.4858 - val_loss: 1.3218 - val_acc: 0.5198\n",
            "Epoch 10/20\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4390 - acc: 0.4883 - val_loss: 1.3035 - val_acc: 0.5309\n",
            "Epoch 11/20\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4519 - acc: 0.4827 - val_loss: 1.2799 - val_acc: 0.5362\n",
            "Epoch 12/20\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.4412 - acc: 0.4846 - val_loss: 1.3298 - val_acc: 0.5434\n",
            "Epoch 13/20\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 1.4398 - acc: 0.4872 - val_loss: 1.3294 - val_acc: 0.5431\n",
            "Epoch 14/20\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.4397 - acc: 0.4917 - val_loss: 1.3391 - val_acc: 0.5251\n",
            "Epoch 15/20\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 1.4361 - acc: 0.4909 - val_loss: 1.2329 - val_acc: 0.5611\n",
            "Epoch 16/20\n",
            "781/781 [==============================] - 23s 30ms/step - loss: 1.4415 - acc: 0.4870 - val_loss: 1.2566 - val_acc: 0.5457\n",
            "Epoch 17/20\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.4465 - acc: 0.4866 - val_loss: 1.2861 - val_acc: 0.5430\n",
            "Epoch 18/20\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.4419 - acc: 0.4900 - val_loss: 1.2546 - val_acc: 0.5433\n",
            "Epoch 19/20\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.4494 - acc: 0.4837 - val_loss: 1.2192 - val_acc: 0.5719\n",
            "Epoch 20/20\n",
            "781/781 [==============================] - 24s 30ms/step - loss: 1.4388 - acc: 0.4889 - val_loss: 1.2163 - val_acc: 0.5633\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f067f9c0da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4EJGHsCxlxv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "ac5c7fd3-aada-4dd6-80af-3b0d6d1fb977"
      },
      "source": [
        "out= model.predict(x_train[0:4])\n",
        "out[3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-75f5349b1bb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}